# ==============================================================================
# LakehousePlumber Job Configuration Template
# ==============================================================================
# 
# This template provides comprehensive configuration options for Databricks
# orchestration jobs generated by the `lhp deps` command.
#
# Usage:
#   1. Copy or rename this file to remove the .tmpl extension
#   2. Customize the settings below for your project
#   3. Pass to lhp deps command: lhp deps --job-config config/job_config.yaml
#
# Documentation: See docs/dependency_analysis.rst for more details
# ==============================================================================

# =============================================================================
# Core Job Settings
# =============================================================================

# Maximum number of concurrent runs of this job
# Prevents resource contention and controls parallel execution
# Default: 1
max_concurrent_runs: 1

# Performance target for job execution
# Options: 
#   - STANDARD: Cost-effective, slower cluster startup
#   - PERFORMANCE_OPTIMIZED: Faster startup, higher cost
# Default: STANDARD
performance_target: STANDARD

# =============================================================================
# Queue Configuration
# =============================================================================

# Job queue settings
# When enabled, jobs wait in queue if max_concurrent_runs is reached
queue:
  enabled: true

# =============================================================================
# Timeouts and Limits
# =============================================================================

# Job-level timeout in seconds
# Uncomment and adjust based on your data volume and processing requirements
# Example: 7200 = 2 hours, 3600 = 1 hour
# timeout_seconds: 3600

# =============================================================================
# Job Tags
# =============================================================================

# Tags for cost tracking, organization, and monitoring
# Uncomment and customize as needed
# tags:
#   environment: dev
#   project: my_project
#   team: data-engineering
#   cost_center: analytics
#   data_domain: your_domain
#   pipeline_type: medallion_architecture

# =============================================================================
# Email Notifications
# =============================================================================

# Configure email alerts for job lifecycle events
# Uncomment and customize recipient emails
# email_notifications:
#   on_start:
#     - data-engineering@company.com
#   on_success:
#     - data-engineering@company.com
#   on_failure:
#     - data-engineering@company.com
#     - data-ops@company.com
#   on_duration_warning_threshold_exceeded:
#     - data-engineering@company.com

# =============================================================================
# Webhook Notifications
# =============================================================================

# Configure webhook notifications for external integrations (Slack, Teams, PagerDuty)
# Uncomment and customize URLs
# webhook_notifications:
#   on_start:
#     - id: slack_notification
#       url: https://hooks.slack.com/services/YOUR/WEBHOOK/URL
#   on_failure:
#     - id: pagerduty_alert
#       url: https://events.pagerduty.com/v2/enqueue

# =============================================================================
# Job Schedule
# =============================================================================

# Quartz cron expression for job scheduling
# Uncomment to enable scheduled execution
# Examples:
#   - "0 0 2 * * ?": Daily at 2 AM
#   - "0 0 */6 * * ?": Every 6 hours
#   - "0 0 8 * * MON-FRI": Weekdays at 8 AM
# schedule:
#   quartz_cron_expression: "0 0 2 * * ?"
#   timezone_id: "America/New_York"
#   pause_status: "UNPAUSED"

# =============================================================================
# Job Permissions
# =============================================================================

# Access control for the job
# Uncomment and configure based on your workspace users/groups
# permissions:
#   - level: CAN_VIEW
#     user_name: user@company.com
#   - level: CAN_MANAGE_RUN
#     group_name: data-engineering
#   - level: CAN_MANAGE
#     group_name: admin

# =============================================================================
# Health Monitoring
# =============================================================================

# Health check and monitoring configuration
# Uncomment to enable health checks
# health:
#   rules:
#     - metric: RUN_DURATION_SECONDS
#       op: GREATER_THAN
#       value: 3600

# =============================================================================
# Notes
# =============================================================================
#
# - All settings here override default values in job_resource.yml.j2
# - User-provided values take precedence over defaults
# - Remove or comment out any settings you don't need to use defaults
# - Validate your configuration before deployment
# - For Databricks-specific constraints, refer to Databricks Jobs API docs
#
# ==============================================================================

