# This pipeline is used to load the customer table from the raw schema into the bronze schema
# Pipeline variable puts the generate files in the same folder for the pipeline to pick up
pipeline: sample_python_func_pipeline
# Flowgroup are conceptual artifacts and has no functional purpose
# there are used to group actions together in the generated files
flowgroup: python_func_flowgroup
#job_name: j_nine
presets:
  - default_delta_properties

actions:
  # Load is not neceseary here as everything is in the same pipeline
  # but it kept in case we decide to split the pipelines
  - name: customer_raw_load
    type: load
    operational_metadata: ["_processing_timestamp"]
    readMode: stream
    source:
      type: delta
      database: "{catalog}.{raw_schema}"
      table: customers
    target: v_customer_raws
    description: "Load customer table from raw schema" 

  - name: customer_bronze_cleanse
    type: transform
    transform_type: python
    source: v_customer_raws
    module_path: "py_functions/sample_func.py"
    function_name: "transform_lrc_data_streaming"
    readMode: stream
    parameters:
      spark: spark
      parameters: {}
    target: v_customer_bronze_cleaneds
    operational_metadata: ["_processing_timestamp"]


  - name: customer_bronze_DQE
    type: transform
    transform_type: data_quality
    source: v_customer_bronze_cleaneds
    target: v_customer_bronze_DQEs
    readMode: stream  
    expectations_file: "expectations/customer_quality.json"
    description: "Apply data quality checks to customer"

  - name: write_customer_bronze
    type: write
    source: v_customer_bronze_DQEs
    write_target:
      type: streaming_table
      database: "{catalog}.{bronze_schema}"
      table: "customers"
      schema: |
        customer_id BIGINT NOT NULL,
        name STRING,
        email STRING,
        region STRING,
        registration_date DATE,
        _source_file_path STRING,
        _processing_timestamp TIMESTAMP
      table_properties:
        tag_name1: tag_value1
        tag_name2: tag_value2

  - name: write_customer_bronze_partitioned
    type: write
    source: v_customer_bronze_DQEs
    write_target:
      type: streaming_table
      database: "{catalog}.{bronze_schema}"
      table: "customers_partitioned"
      partition_columns: ["region", "year"]
      table_properties:
        tag_name1: tag_value1
        tag_name2: tag_value2


  - name: write_customer_bronze_clustered
    type: write
    source: v_customer_bronze_DQEs
    write_target:
      type: streaming_table
      database: "{catalog}.{bronze_schema}"
      table: "customers_clustered"
      cluster_columns: ["customer_id"]
  

  - name: write_customer_bronze_clustered_with_row_filter
    type: write
    source: v_customer_bronze_DQEs
    write_target:
      type: streaming_table
      database: "{catalog}.{bronze_schema}"
      table: "customers_clustered_with_row_filter"
      cluster_columns: ["customer_id"]
      row_filter: "ROW FILTER catalog.schema.customer_access_filter ON (region)"
      schema: |
        customer_id BIGINT NOT NULL,
        name STRING,
        email STRING,
        region STRING,
        registration_date DATE,
        _source_file_path STRING,
        _processing_timestamp TIMESTAMP
