# Generated by LakehousePlumber
# Pipeline: acmi_edw_bronze
# FlowGroup: bronze_layer_tests

from pyspark.sql.functions import *
import dlt

# Pipeline Configuration
PIPELINE_ID = "acmi_edw_bronze"
FLOWGROUP_ID = "bronze_layer_tests"


# ============================================================================
# DATA QUALITY TESTS
# ============================================================================


@dlt.expect_all_or_fail({"row_count_match": "abs(source_count - target_count) <= 0"})
@dlt.table(
    name="tmp_test_customer_bronze_rowcount",
    comment="Ensure all raw customer records reach bronze layer",
    temporary=True,
)
def tmp_test_customer_bronze_rowcount():
    """Ensure all raw customer records reach bronze layer"""
    return spark.sql(
        """
        SELECT * FROM
                      (SELECT COUNT(*) AS source_count FROM acme_edw_tst.edw_raw.customer_raw),
                      (SELECT COUNT(*) AS target_count FROM acme_edw_tst.edw_bronze.customer)
    """
    )


@dlt.expect_all_or_fail(
    {"row_count_match": "abs(source_count + migration_count - target_count) == 0"}
)
@dlt.table(
    name="tmp_test_customer_bronze_rowcount_with_migration",
    comment="Ensure all raw customer records reach bronze layer",
    temporary=True,
)
def tmp_test_customer_bronze_rowcount_with_migration():
    """Ensure all raw customer records reach bronze layer"""
    return spark.sql(
        """
        SELECT
          (SELECT COUNT(*) AS source_count FROM acme_edw_tst.edw_raw.customer_raw) as source_count,
          (SELECT COUNT(*) AS target_count FROM acme_edw_tst.{old_schema}.customer) as migration_count,
          (SELECT COUNT(*) AS target_count FROM acme_edw_tst.edw_bronze.customer) as target_count
    """
    )


@dlt.expect_all_or_fail({"referential_integrity": "ref_customer_id IS NOT NULL"})
@dlt.table(
    name="tmp_test_orders_customer_fk_referential_integrity",
    comment="All orders must have valid customer reference",
    temporary=True,
)
def tmp_test_orders_customer_fk_referential_integrity():
    """All orders must have valid customer reference"""
    return spark.sql(
        """
        SELECT
                      s.*,
                      r.customer_id as ref_customer_id
                    FROM acme_edw_tst.edw_bronze.orders s
                    LEFT JOIN acme_edw_tst.edw_bronze.customer r ON s.customer_id = r.customer_id
    """
    )


@dlt.expect_all_or_fail({"referential_integrity": "ref_o_orderkey IS NOT NULL"})
@dlt.table(
    name="tmp_test_lineitem_orders_fk_referential_integrity",
    comment="All line items must have valid order reference",
    temporary=True,
)
def tmp_test_lineitem_orders_fk_referential_integrity():
    """All line items must have valid order reference"""
    return spark.sql(
        """
        SELECT
                      s.*,
                      r.o_orderkey as ref_o_orderkey
                    FROM acme_edw_tst.edw_bronze.lineitem_africa s
                    LEFT JOIN acme_edw_tst.edw_bronze.orders r ON s.l_orderkey = r.o_orderkey
    """
    )


@dlt.expect_all_or_fail({"referential_integrity": "ref_p_partkey IS NOT NULL"})
@dlt.table(
    name="tmp_test_lineitem_part_fk_referential_integrity",
    comment="All line items must have valid part reference",
    temporary=True,
)
def tmp_test_lineitem_part_fk_referential_integrity():
    """All line items must have valid part reference"""
    return spark.sql(
        """
        SELECT
                      s.*,
                      r.p_partkey as ref_p_partkey
                    FROM acme_edw_tst.edw_bronze.lineitem_africa s
                    LEFT JOIN acme_edw_tst.edw_bronze.part r ON s.l_partkey = r.p_partkey
    """
    )


@dlt.expect_all_or_fail(
    {
        "valid_account_balance": "account_balance >= -999.99 AND account_balance <= 9999.99",
        "valid_market_segment": "market_segment IN ('AUTOMOBILE', 'BUILDING', 'FURNITURE', 'HOUSEHOLD', 'MACHINERY')",
        "valid_phone_format": "LENGTH(REGEXP_REPLACE(phone, '[^0-9]', '')) >= 10",
    }
)
@dlt.table(
    name="tmp_test_bronze_customer_quality_custom_expectations",
    comment="Validate customer data quality rules in bronze layer",
    temporary=True,
)
def tmp_test_bronze_customer_quality_custom_expectations():
    """Validate customer data quality rules in bronze layer"""
    return spark.sql(
        """
        SELECT * FROM acme_edw_tst.edw_bronze.customer
    """
    )


@dlt.expect_all_or_fail({"no_duplicates": "duplicate_count == 0"})
@dlt.table(
    name="tmp_test_lineitem_composite_key_uniqueness",
    comment="Validate lineitem composite key uniqueness",
    temporary=True,
)
def tmp_test_lineitem_composite_key_uniqueness():
    """Validate lineitem composite key uniqueness"""
    return spark.sql(
        """
        SELECT l_orderkey, l_linenumber, COUNT(*) as duplicate_count
                    FROM acme_edw_tst.edw_bronze.lineitem_africa
                    GROUP BY l_orderkey, l_linenumber
                    HAVING COUNT(*) > 1
    """
    )


@dlt.expect_all_or_fail({"schemas_match": "false"})
@dlt.table(
    name="tmp_test_customer_bronze_schema_consistency",
    comment="Ensure customer schema hasn't changed unexpectedly",
    temporary=True,
)
def tmp_test_customer_bronze_schema_consistency():
    """Ensure customer schema hasn't changed unexpectedly"""
    return spark.sql(
        """
        WITH source_schema AS (
                      SELECT column_name, data_type, ordinal_position
                      FROM information_schema.columns
                      WHERE table_name = 'acme_edw_tst.edw_bronze.customer'
                    ),
                    reference_schema AS (
                      SELECT column_name, data_type, ordinal_position
                      FROM information_schema.columns
                      WHERE table_name = 'acme_edw_tst.edw_bronze.customer_backup'
                    ),
                    schema_diff AS (
                      SELECT
                        COALESCE(s.column_name, r.column_name) as column_name,
                        s.data_type as source_type,
                        r.data_type as reference_type,
                        CASE
                          WHEN s.column_name IS NULL THEN 'missing_in_source'
                          WHEN r.column_name IS NULL THEN 'extra_in_source'
                          WHEN s.data_type != r.data_type THEN 'type_mismatch'
                          ELSE 'match'
                        END as status
                      FROM source_schema s
                      FULL OUTER JOIN reference_schema r ON s.column_name = r.column_name
                    )
                    SELECT * FROM schema_diff WHERE status != 'match'
    """
    )
