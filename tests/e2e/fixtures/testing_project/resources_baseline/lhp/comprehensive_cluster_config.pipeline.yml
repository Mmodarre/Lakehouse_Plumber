# Generated by LakehousePlumber - Bundle Resource for comprehensive_cluster_config
# This baseline demonstrates ALL possible non-default pipeline configuration options
# Used for comprehensive E2E testing of cluster configuration with our template fix

resources:
  pipelines:
    comprehensive_cluster_config_pipeline:
      name: comprehensive_cluster_config_pipeline
      
      # Default Catalog and Schema for the pipeline (managed via databricks.yml variables and LHP)
      catalog: ${var.default_pipeline_catalog}
      schema: ${var.default_pipeline_schema}
      
      serverless: false
      # Compute clusters configuration
      clusters:
        - label: default
          node_type_id: Standard_D16ds_v5
          driver_node_type_id: Standard_D32ds_v5
          policy_id: 1234ABCD1234ABCD
          autoscale:
            min_workers: 2
            max_workers: 10
            mode: ENHANCED

      libraries:
        - glob:
            include: ${workspace.file_path}/generated/${bundle.target}/comprehensive_cluster_config/**
      
      root_path: ${workspace.file_path}/generated/${bundle.target}/comprehensive_cluster_config
      
      configuration:
        bundle.sourcePath: ${workspace.file_path}/generated/${bundle.target}      
      continuous: true      
      photon: true      
      edition: ADVANCED      
      channel: PREVIEW      
      notifications:
        - email_recipients:
            - data-engineering@company.com
            - ops-team@company.com
          alerts:
            - on-update-failure
            - on-update-fatal-failure
            - on-update-success
            - on-flow-failure
      
      tags:
        environment: production
        cost_center: data_platform
        criticality: high
        team: data_engineering
      
      event_log:
        name: pipeline_event_log
        schema: _meta
        catalog: main
      # Additional pipeline configuration options 
      add to your pipeline_config.yaml as needed and pass the file path through the --pipeline-config flag:
 
      # Compute clusters configuration (alternative to serverless)
      # clusters:
      #   - label: default
      #     node_type_id: Standard_D16ds_v5
      #     driver_node_type_id: Standard_D32ds_v5
      #     policy_id: 1234ABCD1234ABCD
      #     autoscale:
      #       min_workers: 1
      #       max_workers: 5
      #       mode: ENHANCED
      
      # Enable continuous processing
      # continuous: false
      
   
      # Enable Photon engine only for classic computer not serverless
      # photon: true
      
      # DLT edition (CORE, PRO, ADVANCED)
      # edition: ADVANCED
      
      # Runtime channel (CURRENT, PREVIEW)
      # channel: CURRENT
      
      # Notification settings
      # notifications:
      #   - email_recipients:
      #       - user@databricks.com
      #     alerts:
      #       - on-update-success
      #       - on-update-failure
      #       - on-update-fatal-failure
      #       - on-flow-failure
      
      # Custom tags only for classic computer not serverless (serverless has its own tags through compute policy)
      # tags:
      #   tag1: val1
      
      # Event log configuration
      # event_log:
      #   name: pipeline_evenlog
      #   schema: _meta
      #   catalog: acmi_edw_dev


