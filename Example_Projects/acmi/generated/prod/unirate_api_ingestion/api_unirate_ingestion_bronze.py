# Generated by LakehousePlumber
# Pipeline: unirate_api_ingestion
# FlowGroup: api_unirate_ingestion_bronze

from pyspark.sql.datasource import DataSource, DataSourceStreamReader, InputPartition
from pyspark.sql.functions import *
from pyspark.sql.types import *
from typing import Iterator, Tuple
import dlt
import json
import os
import requests
import time

# Pipeline Configuration
PIPELINE_ID = "unirate_api_ingestion"
FLOWGROUP_ID = "api_unirate_ingestion_bronze"


# ============================================================================
# CUSTOM DATA SOURCE IMPLEMENTATIONS
# ============================================================================
# The following code was automatically copied from: /Users/mehdi.modarressi/Documents/Coding/Lakehouse_Plumber/Example_Projects/acmi/data_sources/currency_api_source.py
# Used by action: load_currency_exchange


# Real API-powered streaming data source for triggered mode
# TEST CHANGE: This comment was added to test dependency tracking


accessToken = (
    dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()
)


class CurrencyInputPartition(InputPartition):
    """Input partition for currency API data source"""

    def __init__(self, start_time, end_time):
        self.start_time = start_time
        self.end_time = end_time


class CurrencyAPIStreamingDataSource(DataSource):
    """
    Real currency exchange data source powered by UniRateAPI.
    Fetches live exchange rates on each triggered pipeline run.
    """

    @classmethod
    def name(cls):
        return "currency_api_stream"

    def schema(self):
        return """
            base_currency string,
            target_currency string,
            exchange_rate double,
            api_timestamp timestamp,
            fetch_timestamp timestamp,
            rate_change_1h double,
            is_crypto boolean,
            data_source string,
            pipeline_run_id string
        """

    def streamReader(self, schema: StructType):
        return CurrencyAPIStreamingReader(schema, self.options)


class CurrencyAPIStreamingReader(DataSourceStreamReader):
    """Streaming reader that fetches real currency data from UniRateAPI with progress tracking"""

    def __init__(self, schema, options):
        self.schema = schema
        self.options = options
        # Your UniRateAPI key
        self.api_key = options.get("apiKey")
        # Base currencies to fetch
        self.base_currencies = options.get("baseCurrencies", "USD").split(",")

        # Progress tracking setup
        self.progress_path = options.get("progressPath")
        self.min_call_interval_seconds = int(
            options.get("minCallIntervalSeconds", "300")
        )  # 5 minutes default
        self.workspace_url = options.get("workspaceUrl")

        # Simple UC Volume setup like example_progress.py
        self.token = accessToken
        self.progress_file_url = f"https://{self.workspace_url}/api/2.0/fs/files{self.progress_path}progress.json"

        # Load existing progress
        self._load_progress()

    def _load_progress(self):
        """Load progress from UC Volume"""
        headers = {
            "Authorization": f"Bearer {self.token}",
        }
        response = requests.get(self.progress_file_url, headers=headers)

        if response.status_code == 200:
            progress_data = response.json()
            self.last_api_call_time = progress_data.get("last_api_call_time", 0)
            self.total_api_calls = progress_data.get("total_api_calls", 0)
            print(
                f"‚úÖ Loaded progress: last call at {self.last_api_call_time}, total calls: {self.total_api_calls}"
            )
        else:
            # File doesn't exist yet, start fresh
            self.last_api_call_time = 0
            self.total_api_calls = 0
            print("üìù No existing progress found, starting fresh")

    def _save_progress(self):
        """Save progress to UC Volume"""
        url = f"{self.progress_file_url}?overwrite=true"
        headers = {
            "Authorization": f"Bearer {self.token}",
            "Content-Type": "application/json",
        }

        progress_data = {
            "last_api_call_time": self.last_api_call_time,
            "total_api_calls": self.total_api_calls,
            "last_updated": int(time.time()),
            "base_currencies": self.base_currencies,
            "min_call_interval_seconds": self.min_call_interval_seconds,
        }

        data = json.dumps(progress_data)
        response = requests.put(url, headers=headers, data=data)

    def _should_make_api_call(self):
        """Determine if enough time has passed to make a new API call"""
        current_time = int(time.time())
        time_since_last_call = current_time - self.last_api_call_time

        should_call = time_since_last_call >= self.min_call_interval_seconds

        if not should_call:
            remaining_time = self.min_call_interval_seconds - time_since_last_call
            print(
                f"‚è≥ Skipping API call - {remaining_time} seconds remaining until next allowed call"
            )

        return should_call

    def initialOffset(self) -> dict:
        """Returns the initial start offset using loaded progress"""
        import time

        return {
            "fetch_time": int(time.time() * 1000),
            "should_fetch": self._should_make_api_call(),
        }

    def latestOffset(self) -> dict:
        """Returns latest offset - advances only if should fetch"""
        import time

        current_time_ms = int(time.time() * 1000)
        should_fetch = self._should_make_api_call()
        return {"fetch_time": current_time_ms, "should_fetch": should_fetch}

    def partitions(self, start: dict, end: dict):
        """Plans the partitioning of the current microbatch"""
        return [
            CurrencyInputPartition(start.get("fetch_time", 0), end.get("fetch_time", 0))
        ]

    def commit(self, end: dict):
        """Called when the query has finished processing data - save progress if API was called"""
        if end.get("should_fetch", False):
            self._save_progress()

    def read(self, partition) -> Iterator[Tuple]:
        """Fetches real currency exchange data from UniRateAPI with rate limiting"""
        from datetime import datetime
        import builtins

        # Check if we should actually make API calls
        if not self._should_make_api_call():
            print("‚è≥ Skipping API call due to rate limiting")
            return iter([])  # Return empty iterator

        # Update progress tracking
        self.last_api_call_time = int(time.time())
        self.total_api_calls += 1

        # Generate unique run ID for this pipeline execution
        run_id = f"run_{self.total_api_calls}_{int(time.time())}"
        fetch_timestamp = datetime.now()

        print(f"üåê Making API call #{self.total_api_calls} at {fetch_timestamp}")

        # Fetch data for each base currency
        for base_currency in self.base_currencies:
            try:
                # Call UniRateAPI to get current exchange rates
                api_url = f"https://api.unirateapi.com/api/rates"
                params = {"api_key": self.api_key, "from": base_currency}

                response = requests.get(api_url, params=params, timeout=10)

                if response.status_code == 200:
                    data = response.json()

                    # Extract rates from the API response
                    if "rates" in data:
                        rates = data["rates"]
                        api_timestamp = (
                            datetime.now()
                        )  # UniRate doesn't provide exact timestamp

                        # Common target currencies to focus on
                        target_currencies = [
                            "USD",
                            "EUR",
                            "GBP",
                            "JPY",
                            "CHF",
                            "AUD",
                            "CAD",
                            "BTC",
                            "ETH",
                        ]

                        for target_currency in target_currencies:
                            if (
                                target_currency in rates
                                and target_currency != base_currency
                            ):
                                rate = float(rates[target_currency])

                                # Determine if this is a cryptocurrency
                                is_crypto = target_currency in [
                                    "BTC",
                                    "ETH",
                                    "LTC",
                                    "XRP",
                                    "ADA",
                                ]

                                # Simulate rate change (in real implementation, you'd store previous values)
                                # For demo, we'll calculate a small random change
                                import random

                                rate_change_1h = builtins.round(
                                    random.uniform(-0.05, 0.05), 4
                                )

                                yield (
                                    base_currency,
                                    target_currency,
                                    rate,
                                    api_timestamp,
                                    fetch_timestamp,
                                    rate_change_1h,
                                    is_crypto,
                                    "UniRateAPI",
                                    run_id,
                                )

                # Small delay between API calls to be respectful
                time.sleep(0.5)

            except Exception as e:
                print(f"Error fetching data for {base_currency}: {str(e)}")
                # Yield an error record for monitoring
                yield (
                    base_currency,
                    "ERROR",
                    0.0,
                    datetime.now(),
                    fetch_timestamp,
                    0.0,
                    False,
                    f"ERROR: {str(e)}",
                    run_id,
                )


# ============================================================================
# SOURCE VIEWS
# ============================================================================

# Try to register the custom data source
try:
    spark.dataSource.register(CurrencyAPIStreamingDataSource)
except Exception:
    pass  # Ignore if already registered


@dlt.view()
def v_currency_bronze():
    """Load live currency exchange rates from external API"""
    df = (
        spark.readStream.format("currency_api_stream")
        .option("apiKey", "XXX")
        .option("baseCurrencies", "USD,EUR,GBP")
        .option("progressPath", "/Volumes/catalog/schema/checkpoints/")
        .option("minCallIntervalSeconds", "300")
        .option("workspaceUrl", "adb-984752964297111.11.azuredatabricks.net")
        .load()
    )

    # Add operational metadata columns
    df = df.withColumn("_processing_timestamp", current_timestamp())

    return df


# ============================================================================
# TARGET TABLES
# ============================================================================

# Create the streaming table
dlt.create_streaming_table(
    name="acme_edw_prod.edw_bronze.currency_exchange",
    comment="Streaming table: currency_exchange",
)


# Define append flow(s)
@dlt.append_flow(
    target="acme_edw_prod.edw_bronze.currency_exchange",
    name="f_currency_exchange_bronze",
    comment="Append flow to acme_edw_prod.edw_bronze.currency_exchange",
)
def f_currency_exchange_bronze():
    """Append flow to acme_edw_prod.edw_bronze.currency_exchange"""
    # Streaming flow
    df = spark.readStream.table("v_currency_bronze")

    return df
